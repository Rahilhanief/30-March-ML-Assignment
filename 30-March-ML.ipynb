{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbb321ad-85cd-40b2-be34-9ea825a9044f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nElastic net regression is a linear regression technique that uses a penalty term to shrink the \\ncoefficients of the predictors.\\nThe penalty term is a combination of the l1-norm (absolute value) and the l2-norm (square) of the coefficients,\\nweighted by a parameter called alpha.\\nThe main difference between elastic net and lasso or ridge is that elastic net has an additional parameter called lambda,\\nwhich controls the balance between the l1-norm and the l2-norm penalties.\\nWhen lambda is zero, elastic net is equivalent to lasso. When lambda is one, elastic net is equivalent to ridge. \\nWhen lambda is between zero and one, elastic net is a compromise between lasso and ridge.\\nThis allows elastic net to adapt to different situations and data sets.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 1 :\n",
    "\"\"\"\n",
    "Elastic net regression is a linear regression technique that uses a penalty term to shrink the \n",
    "coefficients of the predictors.\n",
    "The penalty term is a combination of the l1-norm (absolute value) and the l2-norm (square) of the coefficients,\n",
    "weighted by a parameter called alpha.\n",
    "The main difference between elastic net and lasso or ridge is that elastic net has an additional parameter called lambda,\n",
    "which controls the balance between the l1-norm and the l2-norm penalties.\n",
    "When lambda is zero, elastic net is equivalent to lasso. When lambda is one, elastic net is equivalent to ridge. \n",
    "When lambda is between zero and one, elastic net is a compromise between lasso and ridge.\n",
    "This allows elastic net to adapt to different situations and data sets.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ed1aa14-3fe2-4c37-823c-c8e25f89f823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nElastic Net first emerged as a result of critique on lasso, whose variable selection can be too dependent \\non data and thus unstable. \\nThe solution is to combine the penalties of ridge regression and lasso to get the best of both worlds.\\nElastic Net aims at minimizing the following loss function:\\n\\nfunction\\nwhere α is the mixing parameter between ridge (α\\u2004=\\u20040) and lasso (α\\u2004=\\u20041).\\n\\nNow, there are two parameters to tune: λ and α. The glmnet package allows to tune λ via cross-validation for a fixed α,\\nbut it does not support α-tuning, so we will turn to caret for this job.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q no. 2 :\n",
    "\"\"\"\n",
    "Elastic Net first emerged as a result of critique on lasso, whose variable selection can be too dependent \n",
    "on data and thus unstable. \n",
    "The solution is to combine the penalties of ridge regression and lasso to get the best of both worlds.\n",
    "Elastic Net aims at minimizing the following loss function:\n",
    "\n",
    "function\n",
    "where α is the mixing parameter between ridge (α = 0) and lasso (α = 1).\n",
    "\n",
    "Now, there are two parameters to tune: λ and α. The glmnet package allows to tune λ via cross-validation for a fixed α,\n",
    "but it does not support α-tuning, so we will turn to caret for this job.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8f49d7d-acc5-4ffe-b977-42f76efb006d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe benefit is that elastic net allows a balance of both penalties, which can result in better performance \\nthan a model with either one or the other penalty on some problems. \\nAnother hyperparameter is provided called “lambda” that controls the weighting of the sum of both penalties\\nto the loss function.\\n\\nDisadvantage of the classical elastic net is that the sequential cross-validation procedure used to determine \\nthe penalty parameters results in overshrinkage of the coefficients.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 3 :\n",
    "\"\"\"\n",
    "The benefit is that elastic net allows a balance of both penalties, which can result in better performance \n",
    "than a model with either one or the other penalty on some problems. \n",
    "Another hyperparameter is provided called “lambda” that controls the weighting of the sum of both penalties\n",
    "to the loss function.\n",
    "\n",
    "Disadvantage of the classical elastic net is that the sequential cross-validation procedure used to determine \n",
    "the penalty parameters results in overshrinkage of the coefficients.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4762a61c-cef6-4001-86fd-06aa8a576e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOne of the benefits of elastic net is that it can handle multicollinearity, which is when some \\npredictors are highly correlated with each other. Lasso can suffer from instability and inconsistency when\\nthere is multicollinearity, as it may arbitrarily select one predictor over another. \\nRidge can handle multicollinearity better, but it may keep too many predictors that are not relevant.\\nElastic net can overcome these problems by selecting a subset of predictors that are correlated, but not redundant.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 4 :\n",
    "\"\"\"\n",
    "One of the benefits of elastic net is that it can handle multicollinearity, which is when some \n",
    "predictors are highly correlated with each other. Lasso can suffer from instability and inconsistency when\n",
    "there is multicollinearity, as it may arbitrarily select one predictor over another. \n",
    "Ridge can handle multicollinearity better, but it may keep too many predictors that are not relevant.\n",
    "Elastic net can overcome these problems by selecting a subset of predictors that are correlated, but not redundant.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "185e36cd-4438-4da9-b7cf-bb742ca2ce05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A regression coefficient describes the size and direction of the relationship between a predictor \\nand the response variable.\\nCoefficients are the numbers by which the values of the term are multiplied in a regression equation.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 5 :\n",
    "'''A regression coefficient describes the size and direction of the relationship between a predictor \n",
    "and the response variable.\n",
    "Coefficients are the numbers by which the values of the term are multiplied in a regression equation.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f550578-3e23-4b6e-a4e1-ab3e03a77b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One way of handling missing values is the deletion of the rows or columns having null values. \\nIf any columns have more than half of the values as null then you can drop the entire column. \\nIn the same way, rows can also be dropped if having one or more columns values as null.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 6 :\n",
    "\"\"\"One way of handling missing values is the deletion of the rows or columns having null values. \n",
    "If any columns have more than half of the values as null then you can drop the entire column. \n",
    "In the same way, rows can also be dropped if having one or more columns values as null.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5145d839-caf2-43a6-9220-a8dd612bc773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ELASTIC NET both perform feature selection and that's their whole purpose, so yes you can use them for this. \\nYou don't need to select top n features, since you can play with the arguments α and λ to get an arbitrary \\nnumber of non-negative coefficients.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 7 :\n",
    "'''ELASTIC NET both perform feature selection and that's their whole purpose, so yes you can use them for this. \n",
    "You don't need to select top n features, since you can play with the arguments α and λ to get an arbitrary \n",
    "number of non-negative coefficients.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff4215eb-26f6-4e92-a538-18fe40b403bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To save the ML model using Pickle all we need to do is pass the model object into the dump() function of Pickle.\\nThis will serialize the object and convert it into a “byte stream” that we can save as a file called model. pkl .'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 8 :\n",
    "'''To save the ML model using Pickle all we need to do is pass the model object into the dump() function of Pickle.\n",
    "This will serialize the object and convert it into a “byte stream” that we can save as a file called model. pkl .'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2c0bff1-d677-444a-9ec8-72c912cae18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pickle is a useful Python tool that allows you to save your ML models, to minimise lengthy re-training \\nand allow you to share, commit, and re-load pre-trained machine learning models. \\nMost data scientists working in ML will use Pickle or Joblib to save their ML model for future use.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 9 :\n",
    "'''Pickle is a useful Python tool that allows you to save your ML models, to minimise lengthy re-training \n",
    "and allow you to share, commit, and re-load pre-trained machine learning models. \n",
    "Most data scientists working in ML will use Pickle or Joblib to save their ML model for future use.'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
